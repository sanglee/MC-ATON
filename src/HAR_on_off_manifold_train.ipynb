{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import uci_har, uci_preprocessing\n",
    "from simulation.make_data import get_dataloader\n",
    "from pathlib import Path\n",
    "from models import HARClassifier, VAE_1D, resnet18_1d\n",
    "\n",
    "from training import har_train, OnManifoldPerturbation_v2, structured_har, structured_resnet\n",
    "\n",
    "from training.trades import trades_loss\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import AverageMeter, concatenate, save_data, load_data\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import os\n",
    "\n",
    "from attacker import LinfPGDAttack\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LatentClf, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, 5, padding=2, stride=2)  # in_channels=3\n",
    "        self.bn1 = nn.BatchNorm1d(64, momentum=0.9)\n",
    "        self.maxpool = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 5, padding=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128, momentum=0.9)\n",
    "        self.fc1 = nn.Linear(128 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.bn3 = nn.BatchNorm1d(256, momentum=0.9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "#         print(out.shape)\n",
    "        out = out.view(x.size(0),-1)\n",
    "        out = self.relu(self.bn3(self.fc1(out)))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adv(net, test_loader, device, epsilon=1.0, alpha=0.01, k=7):\n",
    "    net.eval()\n",
    "    adv = LinfPGDAttack(net, epsilon=epsilon, alpha=alpha, k=k)\n",
    "    \n",
    "    advs = None\n",
    "    correct_ys = None\n",
    "    total = None\n",
    "    total_ys = None\n",
    "    for X, y in test_loader:\n",
    "        adv_x = adv.perturb(X.to(device), y.long().to(device))\n",
    "        out = net(adv_x)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        _, predicted = out.max(1)\n",
    "        idx = ~predicted.eq(y.to(device))\n",
    "        advs = concatenate(advs, adv_x[idx].detach().cpu().numpy())\n",
    "        correct_ys = concatenate(correct_ys, y[idx].detach().cpu().numpy())\n",
    "        total = concatenate(total, adv_x.detach().cpu().numpy())\n",
    "        total_ys = concatenate(total_ys, y.detach().cpu().numpy())\n",
    "        \n",
    "    adv_dataloader = get_dataloader(advs, correct_ys, drop_last=False, shuffle=False)\n",
    "    total_adv_dataloader = get_dataloader(total, total_ys, drop_last=False, shuffle=False)\n",
    "    \n",
    "    return adv_dataloader, advs, correct_ys, total_adv_dataloader\n",
    "\n",
    "def accuracy2(net, test_loader, device):\n",
    "    net.eval()\n",
    "    benign_correct = 0\n",
    "    total_set = 0\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        out = net(X)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        _, predicted = out.max(1)\n",
    "        idx = predicted.eq(y.to(device))\n",
    "        benign_correct += predicted.eq(y.to(device)).sum().item()\n",
    "\n",
    "        total_set += X.size(0)\n",
    "\n",
    "    benign_acc = benign_correct / total_set\n",
    "    print('accuracy: {0}'.format(benign_acc))\n",
    "    return benign_acc, benign_correct, total_set\n",
    "\n",
    "\n",
    "def accuracy(net, test_loader, device, epsilon=1.0, alpha=0.01, k=7):\n",
    "    net.eval()\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total_set = 0\n",
    "    correct_list = None\n",
    "    correct_label = None\n",
    "    adv_list = None\n",
    "    benign_softmax_list = None\n",
    "    correct_softmax_list = None\n",
    "    adversarial_softmax_list = None\n",
    "    correct_adversarial_softmax_list = None\n",
    "\n",
    "    adv = LinfPGDAttack(net, epsilon=epsilon, alpha=alpha, k=k)\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        out = net(X)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        benign_softmax_list = concatenate(benign_softmax_list, out.detach().cpu().numpy())\n",
    "        _, predicted = out.max(1)\n",
    "        idx = predicted.eq(y.to(device))\n",
    "        benign_correct += predicted.eq(y.to(device)).sum().item()\n",
    "\n",
    "        correct_softmax_list = concatenate(correct_softmax_list, out[idx].detach().cpu().numpy())\n",
    "        correct_list = concatenate(correct_list, X[idx].detach().cpu().numpy())\n",
    "        correct_label = concatenate(correct_label, y[idx].detach().cpu().numpy())\n",
    "\n",
    "        adv_x = adv.perturb(X.to(device), y.long().to(device))\n",
    "\n",
    "        perturbation = adv_x - X\n",
    "        out = net(adv_x)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        adversarial_softmax_list = concatenate(adversarial_softmax_list, out.detach().cpu().numpy())\n",
    "        _, predicted = out.max(1)\n",
    "        idx = predicted.eq(y.to(device))\n",
    "        correct_adversarial_softmax_list = concatenate(correct_adversarial_softmax_list, out[idx].detach().cpu().numpy())\n",
    "        adv_correct += predicted.eq(y.to(device)).sum().item()\n",
    "\n",
    "        adv_list = concatenate(adv_list, perturbation.detach().cpu().numpy())\n",
    "\n",
    "        total_set += X.size(0)\n",
    "\n",
    "    benign_acc = benign_correct / total_set\n",
    "    adv_acc = adv_correct / total_set\n",
    "    print('benign accuracy: {0}\\tadversarial accuracy: {1}'.format(benign_acc, adv_acc))\n",
    "    return benign_acc, adv_acc, correct_list, correct_label, adv_list\n",
    "\n",
    "\n",
    "def on_manifold_generation(classifier, vae, l_clf, loader, device, epsilon=0.3, k=7, alpha=0.0784, filter_=False, test_=False):\n",
    "    on_adv = OnManifoldPerturbation_v2(classifier, vae, device, eta=epsilon, k=k, alpha=alpha)\n",
    "    \n",
    "    on_adv_Xs = None\n",
    "    on_ys = None\n",
    "    on_zs = None\n",
    "    on_original_zs = None\n",
    "    attack_succ_idxs = None\n",
    "    orig_X = None\n",
    "    orig_y = None\n",
    "    \n",
    "    print('creating perturbed data..')\n",
    "\n",
    "    for X, y in loader:\n",
    "    #     X = X.reshape((X.shape[0], -1))\n",
    "        z, z_pert, adv_x = on_adv.perturb(X.to(device), y.long().to(device))\n",
    "        on_adv_Xs = concatenate(on_adv_Xs, adv_x.detach().cpu().numpy())\n",
    "        on_zs = concatenate(on_zs, z_pert.detach().cpu().numpy())\n",
    "        on_ys = concatenate(on_ys, y.detach().cpu().numpy())\n",
    "        on_original_zs  = concatenate(on_original_zs, z.detach().cpu().numpy())\n",
    "        orig_X = concatenate(orig_X, X.detach().numpy())\n",
    "        orig_y = concatenate(orig_y, y.detach().numpy())\n",
    "\n",
    "        f_x = classifier(adv_x)\n",
    "        f_x = F.softmax(f_x, dim=1)\n",
    "        _, predicted = f_x.max(1)\n",
    "\n",
    "        idxs = ~predicted.eq(y.to(device))\n",
    "        attack_succ_idxs = concatenate(attack_succ_idxs, idxs.detach().cpu().numpy())\n",
    "\n",
    "    # attack_succ_rate = attack_succ_perturbed.shape[0]/10000\n",
    "    # print(attack_succ_rate)\n",
    "\n",
    "    adv_loader = get_dataloader(on_adv_Xs, on_ys)\n",
    "    z_loader = get_dataloader(on_zs, on_ys)\n",
    "\n",
    "\n",
    "    on_xs = None\n",
    "    on_ys = None\n",
    "    on_preds = None\n",
    "    \n",
    "    print('filtering perturbed data..')\n",
    "\n",
    "    for x_tilde, y in adv_loader:\n",
    "        out, _, _ = vae.encode(x_tilde.to(device))\n",
    "        out = l_clf(out.unsqueeze(1))\n",
    "        out = F.softmax(out, dim=1)\n",
    "        _, pred = out.max(1)\n",
    "\n",
    "        idx =  pred.eq(y.to(device))\n",
    "\n",
    "        on_adv_filtered = x_tilde[idx].detach().cpu().numpy()\n",
    "        on_adv_filtered_label = y[idx].detach().cpu().numpy()\n",
    "\n",
    "        on_xs = concatenate(on_xs, on_adv_filtered)\n",
    "        on_ys = concatenate(on_ys, on_adv_filtered_label)\n",
    "        on_preds = concatenate(on_preds, pred.detach().cpu().numpy())\n",
    "\n",
    "    final_loader = get_dataloader(on_xs, on_ys)\n",
    "#     final_loader = adv_loader\n",
    "    \n",
    "    if filter_:\n",
    "\n",
    "        filtered_onxs = None\n",
    "        filtered_onys = None\n",
    "\n",
    "        print('organizing training data..')\n",
    "\n",
    "        for x_tilde, y in final_loader:\n",
    "            out = classifier(x_tilde.to(device))\n",
    "            f_x = F.softmax(out, dim=1)\n",
    "            _, predicted = f_x.max(1)\n",
    "            idxs = ~predicted.eq(y.to(device))\n",
    "\n",
    "            filtered_onxs = concatenate(filtered_onxs, x_tilde[idxs].detach().numpy())\n",
    "            filtered_onys = concatenate(filtered_onys, y[idxs].detach().numpy())\n",
    "\n",
    "        if test_:\n",
    "            final_loader = get_dataloader(filtered_onxs, filtered_onys)\n",
    "        else:\n",
    "            total_X = concatenate(orig_X, filtered_onxs)\n",
    "            total_y = concatenate(orig_y, filtered_onys)\n",
    "\n",
    "            final_loader = get_dataloader(total_X, total_y)\n",
    "    \n",
    "    return final_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_num = 4\n",
    "device = 'cuda:%d'%cuda_num\n",
    "\n",
    "model_dir='./simulation/HAR_UCI/'\n",
    "vae = VAE_1D(9, 1536)\n",
    "state_dict = torch.load(os.path.join(model_dir, 'vae-epoch{}.pt'.format(95)))\n",
    "vae.load_state_dict(state_dict)\n",
    "vae.to(device)\n",
    "\n",
    "model = HARClassifier()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "\n",
    "l_clf = LatentClf()\n",
    "l_clf.to(device)\n",
    "l_clf.load_state_dict(torch.load(os.path.join(model_dir, 'l_clf.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate on_adv_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "# onadv_loader = on_manifold_generation(model, vae, l_clf, train_loader, device, epsilon=0.07, k=7, alpha=0.01, filter_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([128, 9, 128])\n",
      "torch.Size([19, 9, 128])\n"
     ]
    }
   ],
   "source": [
    "for X, y in onadv_test_loader:\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv1d(9, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_dir='./simulation/HAR_UCI/'\n",
    "# model = HARClassifier()\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "\n",
    "# comp_ratio = 0.9\n",
    "\n",
    "model = resnet18_1d(output_len=6, input_channel=9)\n",
    "model.to(device)\n",
    "\n",
    "my_file = Path('./simulation/HAR_UCI/model-epoch49.pt')\n",
    "model.load_state_dict(torch.load(my_file))\n",
    "model.eval()\n",
    "# on_adv_acc = accuracy2(model, onadv_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_test_loader, _, _, _ = generate_adv(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0, 1912)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2(model, off_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating perturbed data..\n",
      "filtering perturbed data..\n",
      "organizing training data..\n",
      "creating perturbed data..\n",
      "filtering perturbed data..\n",
      "organizing training data..\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.003\n",
    "k = 7\n",
    "alpha = 0.0003\n",
    "\n",
    "onadv_loader = on_manifold_generation(model, vae, l_clf, train_loader, device, epsilon=epsilon, k=k, alpha=alpha, filter_=True)\n",
    "onadv_test_loader = on_manifold_generation(model, vae, l_clf, test_loader, device, epsilon=epsilon, k=k, alpha=alpha, filter_=True, test_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a0c2d0469042f18dabb61449e0da16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.4404\tValidation accuracy: 0.8410\n",
      "Epoch 10\tTrain loss: 0.3228\tValidation accuracy: 0.8707\n",
      "Epoch 15\tTrain loss: 0.2695\tValidation accuracy: 0.8937\n",
      "Epoch 20\tTrain loss: 0.2430\tValidation accuracy: 0.9020\n",
      "benign accuracy: 0.9002375296912114\tadversarial accuracy: 0.7974211062097047\n",
      "accuracy: 0.11278195488721804\n"
     ]
    }
   ],
   "source": [
    "normal_acc, off_acc, on_acc = offadv_comp(0.9, retrain=True, EPOCHs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e78836ef874c368b48035c7cf950bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.2789\tValidation accuracy: 0.8937\n",
      "Epoch 10\tTrain loss: 0.2710\tValidation accuracy: 0.8887\n",
      "Epoch 15\tTrain loss: 0.2596\tValidation accuracy: 0.9127\n",
      "Epoch 20\tTrain loss: 0.2552\tValidation accuracy: 0.9180\n",
      "benign accuracy: 0.9165252799457075\tadversarial accuracy: 0.25517475398710554\n",
      "accuracy: 0.41604010025062654\n"
     ]
    }
   ],
   "source": [
    "normal_acc, off_acc, on_acc = onadv_comp(0.9, onadv_loader, retrain=True, EPOCHs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating perturbed data..\n",
      "filtering perturbed data..\n",
      "organizing training data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb61e8a4cdbb4feb99ad704ff92a726d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.6070\tValidation accuracy: 0.8192\n",
      "Epoch 10\tTrain loss: 0.3977\tValidation accuracy: 0.8913\n",
      "Epoch 15\tTrain loss: 0.3085\tValidation accuracy: 0.8937\n",
      "benign accuracy: 0.8917543264336614\tadversarial accuracy: 0.2480488632507635\n",
      "accuracy: 0.13202247191011235\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.0005\n",
    "k = 7\n",
    "alpha = 0.00005\n",
    "\n",
    "\n",
    "\n",
    "normal_acc, off_acc, on_acc = onadv_comp(comp_ratio, onadv_loader, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3128834355828221\n"
     ]
    }
   ],
   "source": [
    "comp_ratio = 0.9\n",
    "\n",
    "model = resnet18_1d(output_len=6, input_channel=9)\n",
    "model.to(device)\n",
    "\n",
    "my_file = Path('./simulation/HAR_UCI/model-epoch49.pt')\n",
    "model.load_state_dict(torch.load(my_file))\n",
    "model.eval()\n",
    "    \n",
    "on_adv_acc = accuracy2(model, onadv_test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(onadv_loader, './simulation/HAR_UCI/', filename='on_train_loader.pkl')\n",
    "save_data(onadv_test_loader, './simulation/HAR_UCI/', filename='on_test_loader.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onadv_loader = load_data('./simulation/HAR_UCI/on_train_loader.pkl')\n",
    "onadv_test_loader = load_data( './simulation/HAR_UCI/on_test_loader.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trades_iter(model, optimizer, criterion, data_loader, device, comp_ratio=0., step_size=0.01, epsilon=0.07, perturb_steps=7, beta=1.):\n",
    "    model.train()\n",
    "    iteration_loss = AverageMeter()\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # calculate robust loss\n",
    "        loss = trades_loss(model=model,\n",
    "                           x_natural=X,\n",
    "                           y=y,\n",
    "                           optimizer=optimizer,\n",
    "                           device=device,\n",
    "                           step_size=step_size,\n",
    "                           epsilon=epsilon,\n",
    "                           perturb_steps=perturb_steps,\n",
    "                           beta=beta)\n",
    "        \n",
    "        \n",
    "        iteration_loss.update(loss.item(), X.size(0))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if comp_ratio > 0:\n",
    "            idxs, lams = structured_har(model, comp_ratio)\n",
    "    if comp_ratio > 0:\n",
    "        idxs, lams = structured_har(model, comp_ratio)\n",
    "    return iteration_loss.avg\n",
    "\n",
    "def dual_train_iter(model, adv, optimizer, criterion, on_loader, train_loader, device, comp_ratio=0.):\n",
    "    model.train()\n",
    "    \n",
    "    iteration_loss = AverageMeter()\n",
    "    for i, ((X, y), (X2, y2)) in enumerate(zip(train_loader, on_loader)):\n",
    "        X, y = X.to(device), y.long().to(device)\n",
    "        X2, y2 = X2.to(device), y2.long().to(device)\n",
    "        X1 = adv.perturb(X, y)\n",
    "        \n",
    "        out = model(X1)\n",
    "        out2 = model(X2)\n",
    "        \n",
    "        out = torch.cat((out, out2))\n",
    "        ys = torch.cat((y, y2))\n",
    "\n",
    "        l = criterion(out, ys)\n",
    "\n",
    "        iteration_loss.update(l.item(), ys.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if comp_ratio > 0:\n",
    "            idxs, lams = structured_har(model, comp_ratio)\n",
    "    if comp_ratio > 0:\n",
    "        idxs, lams = structured_har(model, comp_ratio)\n",
    "    return iteration_loss.avg\n",
    "\n",
    "\n",
    "\n",
    "def adv_train_iter(model, adv, optimizer, criterion, data_loader, device, comp_ratio=0.):\n",
    "    model.train()\n",
    "    \n",
    "    iteration_loss = AverageMeter()\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.long().to(device)\n",
    "        \n",
    "        adv_x = adv.perturb(X, y.long())\n",
    "\n",
    "        output = model(adv_x)\n",
    "\n",
    "        loss = criterion(output, y.long())\n",
    "\n",
    "        iteration_loss.update(loss.item(), X.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if comp_ratio > 0:\n",
    "            idxs, lams = structured_har(model, comp_ratio)\n",
    "    if comp_ratio > 0:\n",
    "        idxs, lams = structured_har(model, comp_ratio)\n",
    "    return iteration_loss.avg\n",
    "\n",
    "def train_iter(model, optimizer, criterion, data_loader, device, comp_ratio=0.):\n",
    "    model.train()\n",
    "    iteration_loss = AverageMeter()\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        output = model(X)\n",
    "\n",
    "        loss = criterion(output, y.long())\n",
    "\n",
    "        iteration_loss.update(loss.item(), X.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if comp_ratio > 0:\n",
    "            idxs, lams = structured_har(model, comp_ratio)\n",
    "#             print(model.conv1.weight.data)\n",
    "    if comp_ratio > 0:\n",
    "        idxs, lams = structured_har(model, comp_ratio)\n",
    "    return iteration_loss.avg\n",
    "\n",
    "def test_iter(model, data_loader, device, check_adv=False, epsilon=0.3, alpha=0.0073, k=7):\n",
    "    model.eval()\n",
    "    normal_acc = AverageMeter()\n",
    "\n",
    "    if check_adv:\n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "        off_acc = AverageMeter()\n",
    "\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        output = model(X)\n",
    "\n",
    "        out = F.softmax(output, dim=1)\n",
    "        _, predicted = out.max(1)\n",
    "        idx = predicted.eq(y)\n",
    "\n",
    "        acc = idx.sum().item() / X.size(0)\n",
    "        normal_acc.update(acc)\n",
    "\n",
    "        if check_adv:\n",
    "            adv_x = adv.perturb(X, y.long())\n",
    "\n",
    "            out = model(adv_x)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            _, predicted = out.max(1)\n",
    "            idx = predicted.eq(y)\n",
    "\n",
    "            acc = idx.sum().item() / X.size(0)\n",
    "            off_acc.update(acc)\n",
    "\n",
    "    if check_adv:\n",
    "        return normal_acc.avg, off_acc.avg\n",
    "    else:\n",
    "        return normal_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trades_comp(comp_ratio, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    \n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-trades-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = trades_iter(model, optimizer, criterion, train_loader, device, comp_ratio, step_size=alpha, epsilon=epsilon, perturb_steps=k, beta=1.)\n",
    "#             train_loss = train_iter(model, optimizer, criterion, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-trades-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def offadv_comp(comp_ratio, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-offadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "        \n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = adv_train_iter(model, adv, optimizer, criterion, train_loader, device, comp_ratio=comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-offadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "    \n",
    "def dualadv_comp(comp_ratio, onadv_loader, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-dualadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "        \n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = dual_train_iter(model, adv, optimizer, criterion, onadv_loader, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-dualadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "\n",
    "def onadv_comp(comp_ratio, onadv_loader, retrain=False, EPOCHs=15, save=True):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-onadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = train_iter(model, optimizer, criterion, onadv_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 and save:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-onadv-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "\n",
    "\n",
    "\n",
    "def benign_comp(comp_ratio, retrain=False, EPOCHs=15):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    \n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-model-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    print(my_file)\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    if comp_ratio == 0.:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "        model.eval()\n",
    "    \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = train_iter(model, optimizer, criterion, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-model-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9002375296912114\n"
     ]
    }
   ],
   "source": [
    "Path('./simulation/HAR_UCI/model-epoch49.pt')\n",
    "\n",
    "comp_ratio = 1.\n",
    "\n",
    "model = resnet18_1d(output_len=6, input_channel=9)\n",
    "model.to(device)\n",
    "\n",
    "my_file = Path('./simulation/HAR_UCI/comp100_0-resnet-epoch19.pt')\n",
    "model.load_state_dict(torch.load(my_file))\n",
    "model.eval()\n",
    "    \n",
    "on_adv_acc = accuracy2(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2182e-01,  3.4760e-02,  2.1399e-01,  1.0390e-01,  8.9060e-02,\n",
       "        -1.2481e-01,  1.3397e-01, -2.6097e-01, -1.1569e-01, -3.6186e-02,\n",
       "         3.1360e-02, -6.8807e-03,  1.2096e-01,  1.4558e-01, -2.6061e-01,\n",
       "        -2.0990e-01, -3.4287e-01, -2.0954e-01, -5.6565e-02,  1.0485e-01,\n",
       "         2.6357e-01, -1.0278e-01, -4.2792e-02, -1.7414e-01, -8.6568e-02,\n",
       "        -1.0691e-01, -6.9222e-02,  3.3895e-01,  4.0046e-01, -1.7424e-02,\n",
       "        -1.5126e-01, -1.3848e-01, -1.0038e-01, -1.6331e-03, -6.9561e-02,\n",
       "        -6.8052e-04,  7.5151e-02,  2.3516e-01, -2.3290e-01, -1.5466e-01,\n",
       "        -8.1470e-02,  2.0137e-01,  6.1631e-01,  5.2196e-01,  5.5525e-01,\n",
       "         3.8745e-01,  4.3791e-01,  4.2734e-01,  4.3617e-01, -6.1679e-01,\n",
       "         1.8969e-01,  3.4669e-01,  1.9619e-01,  3.7165e-01,  4.2038e-01,\n",
       "         5.8306e-01, -1.0666e+00, -1.0356e-02, -8.6998e-03, -4.5606e-02,\n",
       "         1.8110e-01,  4.2872e-01,  5.6085e-01], device='cuda:4')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trades_comp(comp_ratio, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    \n",
    "    model = resnet18_1d(output_len=6, input_channel=9)\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-trades-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model-epoch49.pt')))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = trades_iter(model, optimizer, criterion, train_loader, device, comp_ratio, step_size=alpha, epsilon=epsilon, perturb_steps=k, beta=1.)\n",
    "#             train_loss = train_iter(model, optimizer, criterion, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-trades-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "\n",
    "\n",
    "def offadv_comp(comp_ratio, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = resnet18_1d(output_len=6, input_channel=9)\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-offadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model-epoch49.pt')))\n",
    "        \n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = adv_train_iter(model, adv, optimizer, criterion, train_loader, device, comp_ratio=comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-offadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "    \n",
    "def dualadv_comp(comp_ratio, onadv_loader, retrain=False, EPOCHs=15, epsilon=0.07, k=7, alpha=0.01):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = resnet18_1d(output_len=6, input_channel=9)\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-dualadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model-epoch49.pt')))\n",
    "        \n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = dual_train_iter(model, adv, optimizer, criterion, onadv_loader, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-dualadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)    \n",
    "\n",
    "    print(normal)\n",
    "    \n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "\n",
    "def onadv_comp(comp_ratio, onadv_loader, retrain=False, EPOCHs=15, save=True):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    model = resnet18_1d(output_len=6, input_channel=9)\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-onadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model-epoch49.pt')))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = train_iter(model, optimizer, criterion, onadv_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0 and save:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-onadv-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    \n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal\n",
    "\n",
    "\n",
    "def benign_comp(comp_ratio, retrain=False, EPOCHs=15):\n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    \n",
    "    model = resnet18_1d(output_len=6, input_channel=9)\n",
    "    model.to(device)\n",
    "    \n",
    "    my_file = Path('./simulation/HAR_UCI/comp{}-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), 19))\n",
    "    print(my_file)\n",
    "    \n",
    "    if comp_ratio == 0:\n",
    "        my_file = Path('./simulation/HAR_UCI/model-epoch49.pt')\n",
    "    \n",
    "    if my_file.exists() and not retrain:\n",
    "        model.load_state_dict(torch.load(my_file))\n",
    "        model.eval()\n",
    "    \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "        \n",
    "    else:\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model-epoch49.pt')))\n",
    "    \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "        scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHs)):\n",
    "            train_loss = train_iter(model, optimizer, criterion, train_loader, device, comp_ratio)\n",
    "            val_acc = test_iter(model, test_loader, device)\n",
    "            scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "                torch.save(model.state_dict(),\n",
    "                               os.path.join(model_dir,\n",
    "                                            'comp{}-resnet-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "            \n",
    "        \n",
    "#         benign_acc, off_adv_acc, correct_list, correct_label, adv_list = accuracy(model, test_loader, device, epsilon=0.07, k=7, alpha=0.01)\n",
    "#         on_adv_acc = accuracy2(model, onadv_test_loader, device)\n",
    "    benign_acc, benign_correct, benign_total = accuracy2(model, test_loader, device)\n",
    "    off_adv_acc, _, _ = accuracy2(model, off_test_loader, device)\n",
    "    on_adv_acc, on_correct, on_total = accuracy2(model, onadv_test_loader, device)\n",
    "    \n",
    "#     normal = (on_correct + benign_correct) / (benign_total + on_total)\n",
    "    normal = (on_total/benign_total * benign_correct + on_correct) / (2 * on_total)\n",
    "    \n",
    "    print(normal)\n",
    "    \n",
    "    return benign_acc, off_adv_acc, on_adv_acc, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423a9c0b01f44ae59a2a3398407d62a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign accuracy: 0.7553444180522565\tadversarial accuracy: 0.5890736342042755\n",
      "accuracy: 0.0835509138381201\n"
     ]
    }
   ],
   "source": [
    "be, off, on = offadv_comp(0.5, retrain=True, EPOCHs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bed912d4d546968519db353a251bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign accuracy: 0.8995588734306074\tadversarial accuracy: 0.19409569053274517\n",
      "accuracy: 0.3785900783289817\n"
     ]
    }
   ],
   "source": [
    "be, off, on = onadv_comp(0.5, onadv_loader, retrain=True, EPOCHs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9256871394638616\n",
      "accuracy: 0.0\n",
      "accuracy: 0.0\n",
      "accuracy: 0.9436715303698676\n",
      "accuracy: 0.0246965257429887\n",
      "accuracy: 0.41604010025062654\n",
      "accuracy: 0.8520529351883271\n",
      "accuracy: 0.8656341565508581\n",
      "accuracy: 0.11278195488721804\n",
      "accuracy: 0.8707159823549372\n",
      "accuracy: 0.8668899120971117\n",
      "accuracy: 0.11278195488721804\n",
      "accuracy: 0.9409569053274517\n",
      "accuracy: 0.5429049811636668\n",
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "be, off, on = benign_comp(0., retrain=False, EPOCHs=20)\n",
    "be, off, on = onadv_comp(0., onadv_loader, retrain=False, EPOCHs=20)\n",
    "be, off, on = offadv_comp(0., retrain=False, EPOCHs=20)\n",
    "be, off, on = dualadv_comp(0., onadv_loader, retrain=False, EPOCHs=20)\n",
    "be, off, on = trades_comp(0., retrain=False, EPOCHs=20)\n",
    "\n",
    "\n",
    "#     normal_acc, off_acc, on_acc = benign_comp(comp_ratio, retrain=retrain)\n",
    "#     normal['normal'].append(normal_acc)\n",
    "#     normal['off'].append(off_acc)\n",
    "#     normal['on'].append(on_acc)\n",
    "#     # onadv train comp\n",
    "#     normal_acc, off_acc, on_acc = onadv_comp(comp_ratio, onadv_loader, retrain=True)\n",
    "#     onadv['normal'].append(normal_acc)\n",
    "#     onadv['off'].append(off_acc)\n",
    "#     onadv['on'].append(on_acc)\n",
    "#     # offadv train comp\n",
    "#     normal_acc, off_acc, on_acc = offadv_comp(comp_ratio, retrain=True)\n",
    "#     offadv['normal'].append(normal_acc)\n",
    "#     offadv['off'].append(off_acc)\n",
    "#     offadv['on'].append(on_acc)\n",
    "#     # onoffadv train comp\n",
    "#     normal_acc, off_acc, on_acc = dualadv_comp(comp_ratio, onadv_loader, retrain=True)\n",
    "#     dualadv['normal'].append(normal_acc)\n",
    "#     dualadv['off'].append(off_acc)\n",
    "#     dualadv['on'].append(on_acc)\n",
    "#     # trades train comp\n",
    "#     normal_acc, off_acc, on_acc = trades_comp(comp_ratio, retrain=True)\n",
    "#     trades['normal'].append(normal_acc)\n",
    "#     trades['off'].append(off_acc)\n",
    "#     trades['on'].append(on_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d Resnet train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d654f24e56f04aeea92d71ad5318bb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.0911\tValidation accuracy: 0.9203\n",
      "Epoch 10\tTrain loss: 0.0844\tValidation accuracy: 0.9237\n",
      "Epoch 15\tTrain loss: 0.0840\tValidation accuracy: 0.9203\n",
      "Epoch 20\tTrain loss: 0.0754\tValidation accuracy: 0.9333\n",
      "Epoch 25\tTrain loss: 0.0712\tValidation accuracy: 0.9330\n",
      "Epoch 30\tTrain loss: 0.0591\tValidation accuracy: 0.9320\n",
      "Epoch 35\tTrain loss: 0.0584\tValidation accuracy: 0.9243\n",
      "Epoch 40\tTrain loss: 0.0677\tValidation accuracy: 0.9303\n",
      "Epoch 45\tTrain loss: 0.0523\tValidation accuracy: 0.9287\n",
      "Epoch 50\tTrain loss: 0.0488\tValidation accuracy: 0.9270\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "\n",
    "model = resnet18_1d(output_len=6, input_channel=9)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    train_loss = train_iter(model, optimizer, criterion, train_loader, device, 0)\n",
    "    val_acc = test_iter(model, test_loader, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "        torch.save(model.state_dict(),\n",
    "                       os.path.join(model_dir,\n",
    "                                    'model-epoch{}.pt'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "\n",
    "model = resnet18_1d(output_len=6, input_channel=9)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.91)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[55, 75, 90], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    train_loss = train_iter(model, optimizer, criterion, train_loader, device, 0.5)\n",
    "    val_acc = test_iter(model, test_loader, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch {}\\tTrain loss: {:.4f}\\tValidation accuracy: {:.4f}'.format(epoch + 1, train_loss, val_acc))\n",
    "        torch.save(model.state_dict(),\n",
    "                       os.path.join(model_dir,\n",
    "                                    'comp{}-resnet-epoch{}.pt'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression ratio of 0.000\n",
      "normal\n",
      "simulation/HAR_UCI/comp0_0-model-epoch19.pt\n",
      "accuracy: 0.9097387173396675\n",
      "accuracy: 0.0\n",
      "accuracy: 0.0\n",
      "0.4548693586698337\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae83e6fbfa745c38d9b42e0cb9a0a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.2381\tValidation accuracy: 0.9067\n",
      "Epoch 10\tTrain loss: 0.2291\tValidation accuracy: 0.9120\n",
      "Epoch 15\tTrain loss: 0.2222\tValidation accuracy: 0.9087\n",
      "Epoch 20\tTrain loss: 0.2198\tValidation accuracy: 0.9093\n",
      "accuracy: 0.9077027485578555\n",
      "accuracy: 0.3169456066945607\n",
      "accuracy: 0.4051948051948052\n",
      "0.6564487768763303\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388f8e59a87f48f68cb69597d4595883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3944\tValidation accuracy: 0.8563\n",
      "Epoch 10\tTrain loss: 0.3035\tValidation accuracy: 0.8613\n",
      "Epoch 15\tTrain loss: 0.2635\tValidation accuracy: 0.8557\n",
      "Epoch 20\tTrain loss: 0.2502\tValidation accuracy: 0.8633\n",
      "accuracy: 0.8608754665761792\n",
      "accuracy: 0.7583682008368201\n",
      "accuracy: 0.12207792207792208\n",
      "0.4914766943270506\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86148260cfee4c9abc8a34d41daa1450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3311\tValidation accuracy: 0.8933\n",
      "Epoch 10\tTrain loss: 0.2915\tValidation accuracy: 0.9027\n",
      "Epoch 15\tTrain loss: 0.2719\tValidation accuracy: 0.9133\n",
      "Epoch 20\tTrain loss: 0.2558\tValidation accuracy: 0.9137\n",
      "accuracy: 0.9121140142517815\n",
      "accuracy: 0.7646443514644351\n",
      "accuracy: 0.4051948051948052\n",
      "0.6586544097232934\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c007405010f41b6a21eb899cc201fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3775\tValidation accuracy: 0.8813\n",
      "Epoch 10\tTrain loss: 0.3116\tValidation accuracy: 0.8973\n",
      "Epoch 15\tTrain loss: 0.2824\tValidation accuracy: 0.8853\n",
      "Epoch 20\tTrain loss: 0.2471\tValidation accuracy: 0.9027\n",
      "accuracy: 0.9009161859518154\n",
      "accuracy: 0.772489539748954\n",
      "accuracy: 0.0\n",
      "0.45045809297590766\n",
      "compression ratio of 0.300\n",
      "normal\n",
      "simulation/HAR_UCI/comp30_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70da12f561124aca944b42aaf9366b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.0637\tValidation accuracy: 0.9113\n",
      "Epoch 10\tTrain loss: 0.0654\tValidation accuracy: 0.8943\n",
      "Epoch 15\tTrain loss: 0.0574\tValidation accuracy: 0.9200\n",
      "Epoch 20\tTrain loss: 0.0561\tValidation accuracy: 0.9177\n",
      "accuracy: 0.9161859518154055\n",
      "accuracy: 0.06694560669456066\n",
      "accuracy: 0.0\n",
      "0.45809297590770276\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e781f7a1a4ce4d5cb581787b3020dcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.2520\tValidation accuracy: 0.9197\n",
      "Epoch 10\tTrain loss: 0.2279\tValidation accuracy: 0.9263\n",
      "Epoch 15\tTrain loss: 0.2232\tValidation accuracy: 0.9163\n",
      "Epoch 20\tTrain loss: 0.2181\tValidation accuracy: 0.9130\n",
      "accuracy: 0.9114353579911775\n",
      "accuracy: 0.24267782426778242\n",
      "accuracy: 0.4051948051948052\n",
      "0.6583150815929912\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478761f06aa4427a8c6fcfd26a5a5f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.4237\tValidation accuracy: 0.8337\n",
      "Epoch 10\tTrain loss: 0.3206\tValidation accuracy: 0.8633\n",
      "Epoch 15\tTrain loss: 0.2804\tValidation accuracy: 0.8767\n",
      "Epoch 20\tTrain loss: 0.2692\tValidation accuracy: 0.8630\n",
      "accuracy: 0.8605361384458772\n",
      "accuracy: 0.7327405857740585\n",
      "accuracy: 0.12207792207792208\n",
      "0.4913070302618996\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2ed9e861cf4a73b8ab843fe1cb045e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3481\tValidation accuracy: 0.8757\n",
      "Epoch 10\tTrain loss: 0.3012\tValidation accuracy: 0.9087\n",
      "Epoch 15\tTrain loss: 0.2922\tValidation accuracy: 0.8953\n",
      "Epoch 20\tTrain loss: 0.2702\tValidation accuracy: 0.9003\n",
      "accuracy: 0.8985408890397014\n",
      "accuracy: 0.8091004184100419\n",
      "accuracy: 0.4051948051948052\n",
      "0.6518678471172532\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac05419a750b41e88e76b7720ec2228b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3664\tValidation accuracy: 0.8823\n",
      "Epoch 10\tTrain loss: 0.3102\tValidation accuracy: 0.8933\n",
      "Epoch 15\tTrain loss: 0.2804\tValidation accuracy: 0.8800\n",
      "Epoch 20\tTrain loss: 0.2516\tValidation accuracy: 0.8937\n",
      "accuracy: 0.8917543264336614\n",
      "accuracy: 0.7447698744769874\n",
      "accuracy: 0.12207792207792208\n",
      "0.5069161242557917\n",
      "compression ratio of 0.500\n",
      "normal\n",
      "simulation/HAR_UCI/comp50_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cb4632c6f84f65afb9895925446199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.0866\tValidation accuracy: 0.9030\n",
      "Epoch 10\tTrain loss: 0.0691\tValidation accuracy: 0.9083\n",
      "Epoch 15\tTrain loss: 0.0844\tValidation accuracy: 0.8753\n",
      "Epoch 20\tTrain loss: 0.0645\tValidation accuracy: 0.9090\n",
      "accuracy: 0.9073634204275535\n",
      "accuracy: 0.2907949790794979\n",
      "accuracy: 0.0\n",
      "0.4536817102137767\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834029e2ebfe43269109b25ac8c6a08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.2696\tValidation accuracy: 0.9080\n",
      "Epoch 10\tTrain loss: 0.2437\tValidation accuracy: 0.9110\n",
      "Epoch 15\tTrain loss: 0.2383\tValidation accuracy: 0.9073\n",
      "Epoch 20\tTrain loss: 0.2308\tValidation accuracy: 0.9140\n",
      "accuracy: 0.9124533423820834\n",
      "accuracy: 0.33838912133891214\n",
      "accuracy: 0.4051948051948052\n",
      "0.6588240737884443\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f653637e6766470ebdea0fd389146c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.4807\tValidation accuracy: 0.8350\n",
      "Epoch 10\tTrain loss: 0.3654\tValidation accuracy: 0.8450\n",
      "Epoch 15\tTrain loss: 0.3160\tValidation accuracy: 0.8403\n",
      "Epoch 20\tTrain loss: 0.2682\tValidation accuracy: 0.8317\n",
      "accuracy: 0.8286392941974889\n",
      "accuracy: 0.7494769874476988\n",
      "accuracy: 0.12207792207792208\n",
      "0.47535860813770553\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1d675b545149fc9ec09a49fe0d5c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3771\tValidation accuracy: 0.9140\n",
      "Epoch 10\tTrain loss: 0.3286\tValidation accuracy: 0.8967\n",
      "Epoch 15\tTrain loss: 0.2978\tValidation accuracy: 0.9080\n",
      "Epoch 20\tTrain loss: 0.3077\tValidation accuracy: 0.9143\n",
      "accuracy: 0.9131319986426875\n",
      "accuracy: 0.7405857740585774\n",
      "accuracy: 0.4051948051948052\n",
      "0.6591634019187463\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6097774db74f1383bc445eedeca512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.3827\tValidation accuracy: 0.8796\n",
      "Epoch 10\tTrain loss: 0.3173\tValidation accuracy: 0.8620\n",
      "Epoch 15\tTrain loss: 0.2939\tValidation accuracy: 0.8583\n",
      "Epoch 20\tTrain loss: 0.2626\tValidation accuracy: 0.8796\n",
      "accuracy: 0.8778418730912793\n",
      "accuracy: 0.7416317991631799\n",
      "accuracy: 0.12207792207792208\n",
      "0.49995989758460063\n",
      "compression ratio of 0.700\n",
      "normal\n",
      "simulation/HAR_UCI/comp70_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f20c4e1ac2e4444bdbef53166124291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.1229\tValidation accuracy: 0.8619\n",
      "Epoch 10\tTrain loss: 0.1033\tValidation accuracy: 0.9003\n",
      "Epoch 15\tTrain loss: 0.0876\tValidation accuracy: 0.9123\n",
      "Epoch 20\tTrain loss: 0.0885\tValidation accuracy: 0.9013\n",
      "accuracy: 0.8995588734306074\n",
      "accuracy: 0.3143305439330544\n",
      "accuracy: 0.0\n",
      "0.4497794367153037\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefec4319a4e49eca10b661e864832a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.4224\tValidation accuracy: 0.8707\n",
      "Epoch 10\tTrain loss: 0.2925\tValidation accuracy: 0.8820\n",
      "Epoch 15\tTrain loss: 0.2696\tValidation accuracy: 0.8940\n",
      "Epoch 20\tTrain loss: 0.2580\tValidation accuracy: 0.8930\n",
      "accuracy: 0.8910756701730573\n",
      "accuracy: 0.45502092050209203\n",
      "accuracy: 0.4051948051948052\n",
      "0.6481352376839312\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e352d688034fba83e4395b6436a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.6551\tValidation accuracy: 0.6987\n",
      "Epoch 10\tTrain loss: 0.5922\tValidation accuracy: 0.6721\n",
      "Epoch 15\tTrain loss: 0.5416\tValidation accuracy: 0.7174\n",
      "Epoch 20\tTrain loss: 0.4426\tValidation accuracy: 0.7773\n",
      "accuracy: 0.7733288089582626\n",
      "accuracy: 0.7097280334728033\n",
      "accuracy: 0.12207792207792208\n",
      "0.44770336551809237\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c790efb134ca4d28ba6e3ade584dcc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.5951\tValidation accuracy: 0.8670\n",
      "Epoch 10\tTrain loss: 0.4120\tValidation accuracy: 0.8756\n",
      "Epoch 15\tTrain loss: 0.3493\tValidation accuracy: 0.8542\n",
      "Epoch 20\tTrain loss: 0.3323\tValidation accuracy: 0.8773\n",
      "accuracy: 0.8754665761791652\n",
      "accuracy: 0.7348326359832636\n",
      "accuracy: 0.4051948051948052\n",
      "0.6403306906869852\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2e276b891d4a8b8c4b8c0b3f92f738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.4435\tValidation accuracy: 0.8602\n",
      "Epoch 10\tTrain loss: 0.3776\tValidation accuracy: 0.8901\n",
      "Epoch 15\tTrain loss: 0.3475\tValidation accuracy: 0.8701\n",
      "Epoch 20\tTrain loss: 0.3084\tValidation accuracy: 0.8700\n",
      "accuracy: 0.8737699355276553\n",
      "accuracy: 0.7034518828451883\n",
      "accuracy: 0.12207792207792208\n",
      "0.49792392880278863\n",
      "compression ratio of 0.900\n",
      "normal\n",
      "simulation/HAR_UCI/comp90_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817a4452d29d4a419694c67b09f91fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.2948\tValidation accuracy: 0.8580\n",
      "Epoch 10\tTrain loss: 0.1909\tValidation accuracy: 0.8452\n",
      "Epoch 15\tTrain loss: 0.2024\tValidation accuracy: 0.8820\n",
      "Epoch 20\tTrain loss: 0.1550\tValidation accuracy: 0.8796\n",
      "accuracy: 0.8778418730912793\n",
      "accuracy: 0.2709205020920502\n",
      "accuracy: 0.0\n",
      "0.4389209365456396\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b427537dd8d54f5dad5fe1ddc1860b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.6668\tValidation accuracy: 0.8180\n",
      "Epoch 10\tTrain loss: 0.3998\tValidation accuracy: 0.8706\n",
      "Epoch 15\tTrain loss: 0.3275\tValidation accuracy: 0.8746\n",
      "Epoch 20\tTrain loss: 0.2954\tValidation accuracy: 0.8993\n",
      "accuracy: 0.8975229046487954\n",
      "accuracy: 0.2730125523012552\n",
      "accuracy: 0.4051948051948052\n",
      "0.6513588549218002\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dc4928d4ed4ab4a685c9e8d2f7ea6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.0131\tValidation accuracy: 0.4727\n",
      "Epoch 10\tTrain loss: 0.6692\tValidation accuracy: 0.6374\n",
      "Epoch 15\tTrain loss: 0.6283\tValidation accuracy: 0.6523\n",
      "Epoch 20\tTrain loss: 0.6032\tValidation accuracy: 0.6278\n",
      "accuracy: 0.6321683067526298\n",
      "accuracy: 0.41161087866108786\n",
      "accuracy: 0.0\n",
      "0.3160841533763149\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4515580dbd4d5a8aa7ffde726dc296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.7814\tValidation accuracy: 0.7114\n",
      "Epoch 10\tTrain loss: 0.6447\tValidation accuracy: 0.7251\n",
      "Epoch 15\tTrain loss: 0.6012\tValidation accuracy: 0.7061\n",
      "Epoch 20\tTrain loss: 0.5982\tValidation accuracy: 0.7312\n",
      "accuracy: 0.7332880895826264\n",
      "accuracy: 0.5261506276150628\n",
      "accuracy: 0.4051948051948052\n",
      "0.5692414473887157\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9e77b153ef47ec83199dee95cae900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.6557\tValidation accuracy: 0.7567\n",
      "Epoch 10\tTrain loss: 0.5212\tValidation accuracy: 0.8319\n",
      "Epoch 15\tTrain loss: 0.4645\tValidation accuracy: 0.7641\n",
      "Epoch 20\tTrain loss: 0.4155\tValidation accuracy: 0.8717\n",
      "accuracy: 0.8751272480488632\n",
      "accuracy: 0.6553347280334728\n",
      "accuracy: 0.0\n",
      "0.43756362402443155\n",
      "compression ratio of 0.950\n",
      "normal\n",
      "simulation/HAR_UCI/comp95_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eef13ecfdb74f81ae655bee2e237e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 0.9980\tValidation accuracy: 0.6334\n",
      "Epoch 10\tTrain loss: 0.5355\tValidation accuracy: 0.7391\n",
      "Epoch 15\tTrain loss: 0.4143\tValidation accuracy: 0.7554\n",
      "Epoch 20\tTrain loss: 0.3809\tValidation accuracy: 0.7567\n",
      "accuracy: 0.7638276213098066\n",
      "accuracy: 0.38232217573221755\n",
      "accuracy: 0.0\n",
      "0.38191381065490326\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380b2bc14342481f9cbf95083ca98deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.1841\tValidation accuracy: 0.4287\n",
      "Epoch 10\tTrain loss: 0.9390\tValidation accuracy: 0.5414\n",
      "Epoch 15\tTrain loss: 0.8496\tValidation accuracy: 0.7037\n",
      "Epoch 20\tTrain loss: 0.6532\tValidation accuracy: 0.7284\n",
      "accuracy: 0.7349847302341365\n",
      "accuracy: 0.2907949790794979\n",
      "accuracy: 0.4051948051948052\n",
      "0.5700897677144707\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a59ba0873e24a14b8b17907168c0c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.1231\tValidation accuracy: 0.3763\n",
      "Epoch 10\tTrain loss: 1.0566\tValidation accuracy: 0.4503\n",
      "Epoch 15\tTrain loss: 0.9889\tValidation accuracy: 0.4488\n",
      "Epoch 20\tTrain loss: 0.9003\tValidation accuracy: 0.5928\n",
      "accuracy: 0.5965388530709196\n",
      "accuracy: 0.5115062761506276\n",
      "accuracy: 0.12207792207792208\n",
      "0.35930838757442074\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413c146dea9f43258363b657d6925b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.2263\tValidation accuracy: 0.3450\n",
      "Epoch 10\tTrain loss: 1.0665\tValidation accuracy: 0.5857\n",
      "Epoch 15\tTrain loss: 0.9342\tValidation accuracy: 0.6257\n",
      "Epoch 20\tTrain loss: 0.7895\tValidation accuracy: 0.6697\n",
      "accuracy: 0.675262979300984\n",
      "accuracy: 0.524581589958159\n",
      "accuracy: 0.4051948051948052\n",
      "0.5402288922478946\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4958140f438646f79b7d07c2c8436ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.0140\tValidation accuracy: 0.4678\n",
      "Epoch 10\tTrain loss: 0.9661\tValidation accuracy: 0.4541\n",
      "Epoch 15\tTrain loss: 0.9516\tValidation accuracy: 0.4567\n",
      "Epoch 20\tTrain loss: 0.9384\tValidation accuracy: 0.4602\n",
      "accuracy: 0.46080760095011875\n",
      "accuracy: 0.2301255230125523\n",
      "accuracy: 0.11428571428571428\n",
      "0.28754665761791653\n",
      "compression ratio of 0.990\n",
      "normal\n",
      "simulation/HAR_UCI/comp99_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43b2f4bc02141cca0d63e4a18fb5050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7841\tValidation accuracy: 0.1773\n",
      "Epoch 10\tTrain loss: 1.7822\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.2860\tValidation accuracy: 0.4007\n",
      "Epoch 20\tTrain loss: 1.0840\tValidation accuracy: 0.4237\n",
      "accuracy: 0.4312860536138446\n",
      "accuracy: 0.14173640167364016\n",
      "accuracy: 0.11428571428571428\n",
      "0.27278588394977943\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e7afdcb6454aceafd919fa517df664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 10\tTrain loss: 1.7851\tValidation accuracy: 0.1653\n",
      "Epoch 15\tTrain loss: 1.7853\tValidation accuracy: 0.1653\n",
      "Epoch 20\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "accuracy: 0.168306752629793\n",
      "accuracy: 0.2536610878661088\n",
      "accuracy: 0.4051948051948052\n",
      "0.2867507789122991\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f96721f50d645ba8fbeeccaf5c659d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7844\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b79887d63a94e64826908bd25283ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7856\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e73d49e83644dc9bef31992ccf062f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7841\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7831\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "compression ratio of 0.995\n",
      "normal\n",
      "simulation/HAR_UCI/comp99_5-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b66b0dd1884930be40fd9c380d6b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba39ab644634cf0a963e19f94f33786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 10\tTrain loss: 1.7853\tValidation accuracy: 0.1653\n",
      "Epoch 15\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 20\tTrain loss: 1.7851\tValidation accuracy: 0.1653\n",
      "accuracy: 0.168306752629793\n",
      "accuracy: 0.2536610878661088\n",
      "accuracy: 0.4051948051948052\n",
      "0.2867507789122991\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a486ec90727d4f66bde17caa54331160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aeccef19a9498ebe9e1bf4dee16373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7853\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7857\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7854\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7853\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0285cb956de49a2afcb8343003f6383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7841\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7841\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7839\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7710\tValidation accuracy: 0.2790\n",
      "accuracy: 0.2840176450627757\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.199151679674245\n",
      "compression ratio of 0.999\n",
      "normal\n",
      "simulation/HAR_UCI/comp99_9-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242aa3f442ef479782a9b11ba2e3c005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7844\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888b3149a1a64931886cca7d96c407f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7853\tValidation accuracy: 0.1653\n",
      "Epoch 10\tTrain loss: 1.7853\tValidation accuracy: 0.1653\n",
      "Epoch 15\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 20\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "accuracy: 0.168306752629793\n",
      "accuracy: 0.2536610878661088\n",
      "accuracy: 0.4051948051948052\n",
      "0.2867507789122991\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593877f7e51f4cc894338cfe6384c3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa91e3b554c4fe18d442c8c1a5c43b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7859\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7854\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7854\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a57be86e3d4dd9bd9d801c34d28101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7834\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "compression ratio of 1.000\n",
      "normal\n",
      "simulation/HAR_UCI/comp100_0-model-epoch19.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdca3904abe4d02bedf2183e5e76b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7844\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7844\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "on\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8952a41bf91948088cfed6b4686d938b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 10\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "Epoch 15\tTrain loss: 1.7853\tValidation accuracy: 0.1653\n",
      "Epoch 20\tTrain loss: 1.7852\tValidation accuracy: 0.1653\n",
      "accuracy: 0.168306752629793\n",
      "accuracy: 0.2536610878661088\n",
      "accuracy: 0.4051948051948052\n",
      "0.2867507789122991\n",
      "off\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879ef9c2c83e44dda95e432450a9e875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7844\tValidation accuracy: 0.1773\n",
      "Epoch 20\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "dual\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98df1af8e804e22b5c83617edc7c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7855\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7852\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n",
      "trades\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf1a8fa4bd64f17abdb4612db49cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 10\tTrain loss: 1.7843\tValidation accuracy: 0.1790\n",
      "Epoch 15\tTrain loss: 1.7842\tValidation accuracy: 0.1790\n",
      "Epoch 20\tTrain loss: 1.7841\tValidation accuracy: 0.1790\n",
      "accuracy: 0.18221920597217509\n",
      "accuracy: 0.0\n",
      "accuracy: 0.11428571428571428\n",
      "0.1482524601289447\n"
     ]
    }
   ],
   "source": [
    "normal = {\n",
    "    'normal': [],\n",
    "    'off': [],\n",
    "    'on': [],\n",
    "    'onnormal': []\n",
    "}\n",
    "\n",
    "onadv = {\n",
    "    'normal': [],\n",
    "    'off': [],\n",
    "    'on': [],\n",
    "    'onnormal': []\n",
    "}\n",
    "\n",
    "offadv = {\n",
    "    'normal': [],\n",
    "    'off': [],\n",
    "    'on': [],\n",
    "    'onnormal': []\n",
    "}\n",
    "\n",
    "dualadv = {\n",
    "    'normal': [],\n",
    "    'off': [],\n",
    "    'on': [],\n",
    "    'onnormal': []\n",
    "}\n",
    "\n",
    "trades = {\n",
    "    'normal': [],\n",
    "    'off': [],\n",
    "    'on': [],\n",
    "    'onnormal': []\n",
    "}\n",
    "\n",
    "# ratio_list = [0., 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 0.995, 0.999]\n",
    "ratio_list = [0., 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 0.995, 0.999, 1.]\n",
    "\n",
    "for comp_ratio in ratio_list:\n",
    "    retrain = False\n",
    "    print('compression ratio of {:.3f}'.format(comp_ratio))\n",
    "    # benign comp\n",
    "    \n",
    "#     if comp_ratio == 1.:\n",
    "#         retrain = False\n",
    "#     else:\n",
    "    retrain = True\n",
    "    \n",
    "    print('normal')\n",
    "    normal_acc, off_acc, on_acc, onnormal = benign_comp(comp_ratio, retrain=retrain, EPOCHs=20)\n",
    "    normal['normal'].append(normal_acc)\n",
    "    normal['off'].append(off_acc)\n",
    "    normal['on'].append(on_acc)\n",
    "    normal['onnormal'].append(onnormal)\n",
    "    # onadv train comp\n",
    "    print('on')\n",
    "    normal_acc, off_acc, on_acc, onnormal = onadv_comp(comp_ratio, onadv_loader, retrain=retrain, EPOCHs=20)\n",
    "    onadv['normal'].append(normal_acc)\n",
    "    onadv['off'].append(off_acc)\n",
    "    onadv['on'].append(on_acc)\n",
    "    onadv['onnormal'].append(onnormal)\n",
    "    # offadv train comp\n",
    "    print('off')\n",
    "    normal_acc, off_acc, on_acc, onnormal = offadv_comp(comp_ratio, retrain=retrain, EPOCHs=20)\n",
    "    offadv['normal'].append(normal_acc)\n",
    "    offadv['off'].append(off_acc)\n",
    "    offadv['on'].append(on_acc)\n",
    "    offadv['onnormal'].append(onnormal)\n",
    "    # onoffadv train comp\n",
    "    print('dual')\n",
    "    normal_acc, off_acc, on_acc, onnormal = dualadv_comp(comp_ratio, onadv_loader, retrain=retrain, EPOCHs=20)\n",
    "    dualadv['normal'].append(normal_acc)\n",
    "    dualadv['off'].append(off_acc)\n",
    "    dualadv['on'].append(on_acc)\n",
    "    dualadv['onnormal'].append(onnormal)\n",
    "    # trades train comp\n",
    "    print('trades')\n",
    "    normal_acc, off_acc, on_acc, onnormal = trades_comp(comp_ratio, retrain=retrain, EPOCHs=20)\n",
    "    trades['normal'].append(normal_acc)\n",
    "    trades['off'].append(off_acc)\n",
    "    trades['on'].append(on_acc)\n",
    "    trades['onnormal'].append(onnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = {\n",
    "    'normal_train': normal,\n",
    "    'onadv_train': onadv,\n",
    "    'offadv_train': offadv,\n",
    "    'dualadv_train': dualadv,\n",
    "    'trades_train': trades\n",
    "}\n",
    "\n",
    "save_data(total, './simulation/HAR_UCI/', filename='inference_result6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './simulation/HAR_UCI/'\n",
    "model_file = os.path.join(model_dir, 'comp0_0-model-epoch{}.pt'.format(99))\n",
    "\n",
    "state_dict = torch.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation/HAR_UCI/comp0_0-model-epoch99.pt'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./simulation/HAR_UCI/comp0_0-model-epoch99.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_har(comp_ratio, device, model_dir='./simulation/HAR_UCI/'):\n",
    "    state_dict = torch.load(os.path.join(model_dir,\n",
    "                                    'comp{}-model-epoch{}.pt'.format(str(comp_ratio * 100).replace('.', '_'), epoch)))\n",
    "    \n",
    "    train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "    \n",
    "    model = HARClassifier()\n",
    "    model.to(device)\n",
    "    model.load(state_dict)\n",
    "    \n",
    "    acc, off_acc = test_iter(model, test_loader, device, check_adv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9113333333333333, 0.32731205673758873)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, off_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='./simulation/HAR_UCI/'\n",
    "device = 'cuda:%d'%4\n",
    "state_dict = torch.load(os.path.join(model_dir,\n",
    "                                    'comp0_0-model-epoch{}.pt'.format(99)))\n",
    "\n",
    "train_loader, test_loader = uci_har('/workspace/Dataset/TSData/uci_data/np/')\n",
    "\n",
    "model = HARClassifier()\n",
    "model.to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "acc, off_acc = test_iter(model, test_loader, device, check_adv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_iter(model, data_loader, device, check_adv=False, epsilon=0.3, alpha=0.0073, k=7):\n",
    "    \n",
    "    model.eval()\n",
    "    normal_acc = AverageMeter()\n",
    "\n",
    "    if check_adv:\n",
    "        adv = LinfPGDAttack(model, epsilon=epsilon, alpha=alpha, k=k)\n",
    "        off_acc = AverageMeter()\n",
    "\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        output = model(X)\n",
    "\n",
    "        out = F.softmax(output, dim=1)\n",
    "        _, predicted = out.max(1)\n",
    "        idx = predicted.eq(y)\n",
    "\n",
    "        acc = idx.sum().item() / X.size(0)\n",
    "        normal_acc.update(acc)\n",
    "\n",
    "        if check_adv:\n",
    "            adv_x = adv.perturb(X, y.long())\n",
    "\n",
    "            out = model(adv_x)\n",
    "            out = F.softmax(out, dim=1)\n",
    "            _, predicted = out.max(1)\n",
    "            idx = predicted.eq(y)\n",
    "\n",
    "            acc = idx.sum().item() / X.size(0)\n",
    "            off_acc.update(acc)\n",
    "\n",
    "    if check_adv:\n",
    "        return normal_acc.avg, off_acc.avg\n",
    "    else:\n",
    "        return normal_acc.avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
